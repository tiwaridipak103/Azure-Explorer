import numpy as np
import multiprocessing
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Generate random data
def generate_data(seed):
    np.random.seed(seed)
    X = np.random.rand(100, 5)  # 100 samples, 5 features
    y = X @ np.array([2, -3, 1, 4, -2]) + np.random.randn(100)  # Linear relation with noise
    return X, y

# Function to train a linear regression model
def train_linear_regression(seed):
    X, y = generate_data(seed)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    
    return f"Model {seed}: MSE = {mse:.4f}"

# Running 5 linear regression models in parallel
if __name__ == "__main__":
    seeds = [42, 43, 44, 45, 46]  # Different seeds for different datasets
    
    with multiprocessing.Pool(processes=5) as pool:
        results = pool.map(train_linear_regression, seeds)
    
    for res in results:
        print(res)



import multiprocessing as mp

def dipak(c, shared_list):
    shared_list.extend(c)
    print('hi')

if __name__ == "__main__":
    run_with_multiprocessing = True

    if run_with_multiprocessing:
        with mp.Manager() as manager:
            a = manager.list()  # Shared list across processes
            with mp.Pool(processes=3) as pool:
                pool.starmap(dipak, [((1, 2, 3), a)])

            print(list(a))  # Convert shared list to normal list before printing


import multiprocessing as mp

def dipak(c, shared_dict):
    shared_dict.update(c)  # Update shared dictionary
    print('hi')

if __name__ == "__main__":
    run_with_multiprocessing = True

    if run_with_multiprocessing:
        with mp.Manager() as manager:
            a = manager.dict()  # Shared dictionary across processes
            data = [{"x": 1, "y": 2}, {"z": 3}]

            with mp.Pool(processes=3) as pool:
                pool.starmap(dipak, [(d, a) for d in data])

            print(dict(a))  # Convert shared dict to normal dict before printing


import multiprocessing as mp

def dipak(c, shared_list, shared_dict):
    shared_list.extend(c['list'])  # Append values to shared list
    shared_dict.update(c['dict'])  # Update shared dictionary
    print('hi')

if __name__ == "__main__":
    run_with_multiprocessing = True

    if run_with_multiprocessing:
        with mp.Manager() as manager:
            shared_list = manager.list()  # Shared list across processes
            shared_dict = manager.dict()  # Shared dictionary across processes

            data = [
                {"list": [1, 2], "dict": {"a": 1}}, 
                {"list": [3, 4], "dict": {"b": 2}}
            ]

            with mp.Pool(processes=3) as pool:
                pool.starmap(dipak, [(d, shared_list, shared_dict) for d in data])

            print("Final List:", list(shared_list))  # Convert to normal list before printing
            print("Final Dict:", dict(shared_dict))  # Convert to normal dict before printing



import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from multiprocessing import Pool

# Sample dataset
np.random.seed(42)
data = pd.DataFrame({
    'feature1': np.random.rand(100),
    'feature2': np.random.rand(100),
    'target': np.random.randint(0, 2, 100)
})

# Function to train and evaluate a model
def dipak_model(seed):
    # Shuffle data
    np.random.seed(seed)
    shuffled_data = data.sample(frac=1, random_state=seed).reset_index(drop=True)
    
    # Train-test split (80-20)
    train, test = train_test_split(shuffled_data, test_size=0.2, random_state=seed)

    # Data preprocessing (if any)
    X_train = train[['feature1', 'feature2']]
    y_train = train['target']
    X_test = test[['feature1', 'feature2']]
    y_test = test['target']
    
    # Train a Linear Regression model
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # Evaluate the model
    score = model.score(X_test, y_test)
    
    return f"Seed {seed}: Model Score = {score:.4f}"

# Running 10 parallel executions using multiprocessing
if __name__ == "__main__":
    seeds = list(range(10))  # 10 different seeds for different splits
    with Pool(processes=4) as pool:  # Using 4 cores
        results = pool.map(dipak_model, seeds)

    # Print results
    for res in results:
        print(res)