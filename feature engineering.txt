import multiprocessing as mp
import numpy as np
import random
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split, KFold
import lightgbm as lgb

class RandomSearchParallel:
    def __init__(self, model, param_grid, scoring, n_iter=20, n_jobs=4, cv=5):
        self.model = model
        self.param_grid = param_grid
        self.scoring = scoring
        self.n_iter = n_iter  # Total number of random parameter sets to test
        self.n_jobs = min(n_jobs, mp.cpu_count())  # Limit parallel jobs to CPU cores
        self.cv = cv  # Number of cross-validation folds
        self.best_params_ = None
        self.best_score_ = float('inf')
        self.best_model_ = None

    def _train_evaluate(self, params, X, y, result_dict):
        """Trains and evaluates the model using cross-validation"""
        process_name = mp.current_process().name
        print(f"{process_name} - Training with params: {params}")

        kf = KFold(n_splits=self.cv, shuffle=True, random_state=42)
        scores = []

        for train_idx, val_idx in kf.split(X):
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            model = self.model.set_params(**params)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_val)

            score = mean_absolute_error(y_val, y_pred)
            scores.append(score)

        mean_score = np.mean(scores)
        print(f"{process_name} - Mean CV Score: {mean_score}")

        # Store the result in shared dictionary
        result_dict[str(params)] = mean_score

    def fit(self, X, y):
        """Runs Randomized Search with batch-wise multiprocessing"""
        manager = mp.Manager()
        result_dict = manager.dict()  # Shared dict for storing results
        processes = []

        sampled_params = [self._sample_params() for _ in range(self.n_iter)]  # Sample random parameters

        for i, params in enumerate(sampled_params):
            p = mp.Process(target=self._train_evaluate, args=(params, X, y, result_dict))
            p.start()
            processes.append(p)

            # Run in batches of `n_jobs`
            if len(processes) >= self.n_jobs:
                for p in processes:
                    p.join()
                processes = []  # Reset batch

        # Ensure any remaining processes complete
        for p in processes:
            p.join()

        # Find the best parameters based on the lowest score
        self.best_params_, self.best_score_ = min(result_dict.items(), key=lambda x: x[1])
        self.best_model_ = self.model.set_params(**eval(self.best_params_))  # Train best model

        print(f"\nBest Params: {self.best_params_}")
        print(f"Best Score: {self.best_score_}")

    def _sample_params(self):
        """Randomly samples a set of hyperparameters from the grid"""
        return {key: random.choice(values) for key, values in self.param_grid.items()}


# Example Usage:
if __name__ == "__main__":
    from sklearn.datasets import make_regression
    
    # Generate synthetic data
    X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)
    
    # Define parameter grid
    param_grid = {
        'learning_rate': [0.01, 0.05, 0.1],
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 5, 7]
    }

    # Instantiate model
    model = lgb.LGBMRegressor()

    # Run Random Search
    search = RandomSearchParallel(model, param_grid, scoring="neg_mean_absolute_error", n_iter=20, n_jobs=4, cv=5)
    search.fit(X, y)

    print(f"Best Model: {search.best_model_}")


import psutil
import time

# Wait a short time to get an accurate reading
time.sleep(1) 

# Get the percentage usage of each core
cpu_usage_per_core = psutil.cpu_percent(percpu=True)

# Print the usage of each core
for i, usage in enumerate(cpu_usage_per_core):
    print(f"Core {i}: {usage}% used")


import psutil
import matplotlib.pyplot as plt
import time

plt.ion()  # Enable interactive mode

# Initialize the plot
fig, ax = plt.subplots()
bars = ax.bar(range(psutil.cpu_count()), [0] * psutil.cpu_count(), color='blue')

ax.set_ylim(0, 100)
ax.set_xlabel("CPU Core")
ax.set_ylabel("Usage (%)")
ax.set_title("Live CPU Usage per Core")

while True:
    # Get CPU usage for each core
    cpu_usage = psutil.cpu_percent(percpu=True)
    
    # Update bar heights
    for bar, usage in zip(bars, cpu_usage):
        bar.set_height(usage)
    
    # Pause to refresh the plot
    plt.pause(2)


import psutil
import matplotlib.pyplot as plt
import time

plt.ion()  # Turn on interactive mode

fig, ax = plt.subplots()

while True:
    # Get CPU usage for each core
    cpu_usage = psutil.cpu_percent(percpu=True)

    # Clear previous plot
    ax.clear()
    
    # Plot new data
    ax.bar(range(len(cpu_usage)), cpu_usage, color='blue')

    # Set labels and limits
    ax.set_ylim(0, 100)
    ax.set_xlabel("CPU Core")
    ax.set_ylabel("Usage (%)")
    ax.set_title("Live CPU Usage per Core")

    # Draw the updated figure
    plt.draw()
    plt.pause(2)  # Pause for 2 seconds


import psutil
import matplotlib.pyplot as plt
import matplotlib.animation as animation

# Get the number of CPU cores
num_cores = psutil.cpu_count()

# Create figure and axis
fig, ax = plt.subplots()
bars = ax.bar(range(num_cores), [0] * num_cores, color='blue')

# Set labels and limits
ax.set_ylim(0, 100)
ax.set_xlabel("CPU Core")
ax.set_ylabel("Usage (%)")
ax.set_title("Live CPU Usage per Core")

# Function to update the bar chart
def update(frame):
    cpu_usage = psutil.cpu_percent(percpu=True)  # Get CPU usage for each core
    for bar, usage in zip(bars, cpu_usage):
        bar.set_height(usage)  # Update bar heights
    return bars

# Use Matplotlib animation to refresh plot every 2 seconds
ani = animation.FuncAnimation(fig, update, interval=2000, blit=False)

plt.show()


import psutil
import matplotlib.pyplot as plt
import multiprocessing as mp
import time

def get_cpu_usage(queue):
    """Continuously get CPU usage and put it into the queue."""
    while True:
        cpu_usage = psutil.cpu_percent(percpu=True)  # Get CPU usage per core
        queue.put(cpu_usage)  # Put data into the queue
        time.sleep(2)  # Wait for 2 seconds

def plot_cpu_usage(queue):
    """Plot bar chart and update it continuously."""
    num_cores = psutil.cpu_count()
    fig, ax = plt.subplots()
    bars = ax.bar(range(num_cores), [0] * num_cores, color='blue')

    ax.set_ylim(0, 100)
    ax.set_xlabel("CPU Core")
    ax.set_ylabel("Usage (%)")
    ax.set_title("Live CPU Usage per Core")

    plt.ion()  # Turn on interactive mode
    plt.show()

    while True:
        if not queue.empty():
            cpu_usage = queue.get()  # Get latest CPU usage data
            for bar, usage in zip(bars, cpu_usage):
                bar.set_height(usage)  # Update bar heights
            plt.draw()
            plt.pause(0.1)  # Small pause to refresh the plot

if __name__ == "__main__":
    queue = mp.Queue()  # Shared queue for data exchange

    # Start the data collection process
    process = mp.Process(target=get_cpu_usage, args=(queue,))
    process.start()

    # Run the plotting function in the main process
    plot_cpu_usage(queue)

    process.join()

import matplotlib.pyplot as plt
import numpy as np
import time

# Sample data
categories = ['A', 'B', 'C', 'D']
values = np.random.randint(1, 100, size=len(categories))

plt.ion()  # Turn on interactive mode

for _ in range(10):
    plt.clf()  # Clear the figure before plotting a new one
    
    values = np.random.randint(1, 100, size=len(categories))  # Generate new data
    plt.bar(categories, values, color='blue')
    plt.ylim(0, 100)  # Set limit for better visualization

    plt.draw()  # Draw the updated figure
    plt.pause(0.5)  # Pause to see the changes
    
plt.ioff()  # Turn off interactive mode
plt.show()  # Show the final plot