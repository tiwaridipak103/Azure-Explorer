import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

# Example Data (replace with your data)
X = pd.DataFrame(np.random.rand(100, 20))  # 100 samples, 20 features
y = np.random.rand(100)  # Target variable

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a LightGBM model
model = lgb.LGBMRegressor()
model.fit(X_train, y_train)

# Get predictions
y_pred = model.predict(X_train)

# Compute residuals
residuals = y_train - y_pred

# Step 1: Define a threshold for capping residuals (e.g., 95th and 5th percentile)
lower_threshold = np.percentile(residuals, 5)  # 5th percentile
upper_threshold = np.percentile(residuals, 95)  # 95th percentile

# Step 2: Cap the residuals
capped_residuals = np.clip(residuals, lower_threshold, upper_threshold)

# Step 3: Adjust target variable (y_train) by adding capped residuals to predictions
y_train_capped = y_pred + capped_residuals

# Step 4: Retrain the model using the adjusted target variable (y_train_capped)
model_capped = lgb.LGBMRegressor()
model_capped.fit(X_train, y_train_capped)

# Make predictions with the cleaned model
y_pred_capped = model_capped.predict(X_test)

# Evaluate model performance
mae_capped = mean_absolute_error(y_test, y_pred_capped)
print(f"Capped Model MAE: {mae_capped}")