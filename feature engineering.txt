import numpy as np
import multiprocessing
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Generate random data
def generate_data(seed):
    np.random.seed(seed)
    X = np.random.rand(100, 5)  # 100 samples, 5 features
    y = X @ np.array([2, -3, 1, 4, -2]) + np.random.randn(100)  # Linear relation with noise
    return X, y

# Function to train a linear regression model
def train_linear_regression(seed):
    X, y = generate_data(seed)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    
    return f"Model {seed}: MSE = {mse:.4f}"

# Running 5 linear regression models in parallel
if __name__ == "__main__":
    seeds = [42, 43, 44, 45, 46]  # Different seeds for different datasets
    
    with multiprocessing.Pool(processes=5) as pool:
        results = pool.map(train_linear_regression, seeds)
    
    for res in results:
        print(res)



import multiprocessing as mp

def dipak(c, shared_list):
    shared_list.extend(c)
    print('hi')

if __name__ == "__main__":
    run_with_multiprocessing = True

    if run_with_multiprocessing:
        with mp.Manager() as manager:
            a = manager.list()  # Shared list across processes
            with mp.Pool(processes=3) as pool:
                pool.starmap(dipak, [((1, 2, 3), a)])

            print(list(a))  # Convert shared list to normal list before printing


import multiprocessing as mp

def dipak(c, shared_dict):
    shared_dict.update(c)  # Update shared dictionary
    print('hi')

if __name__ == "__main__":
    run_with_multiprocessing = True

    if run_with_multiprocessing:
        with mp.Manager() as manager:
            a = manager.dict()  # Shared dictionary across processes
            data = [{"x": 1, "y": 2}, {"z": 3}]

            with mp.Pool(processes=3) as pool:
                pool.starmap(dipak, [(d, a) for d in data])

            print(dict(a))  # Convert shared dict to normal dict before printing


import multiprocessing as mp

def dipak(c, shared_list, shared_dict):
    shared_list.extend(c['list'])  # Append values to shared list
    shared_dict.update(c['dict'])  # Update shared dictionary
    print('hi')

if __name__ == "__main__":
    run_with_multiprocessing = True

    if run_with_multiprocessing:
        with mp.Manager() as manager:
            shared_list = manager.list()  # Shared list across processes
            shared_dict = manager.dict()  # Shared dictionary across processes

            data = [
                {"list": [1, 2], "dict": {"a": 1}}, 
                {"list": [3, 4], "dict": {"b": 2}}
            ]

            with mp.Pool(processes=3) as pool:
                pool.starmap(dipak, [(d, shared_list, shared_dict) for d in data])

            print("Final List:", list(shared_list))  # Convert to normal list before printing
            print("Final Dict:", dict(shared_dict))  # Convert to normal dict before printing