import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import colors

# Example correlation dataframe
# Replace this with your actual dataframe
df = pd.DataFrame(np.random.rand(8, 8), columns=list('ABCDEFGH'))

# Calculate correlation matrix
corr = df.corr()

# Custom function to map colors based on conditions
def custom_colormap(value):
    if value > 0.8:
        return '#33cc33'  # Green for values > 0.8
    else:
        return '#0099ff'  # Blue for other values

# Create the heatmap
plt.figure(figsize=(10, 8))
plt.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)

# Annotate the heatmap with correlation values and custom colors
for i in range(corr.shape[0]):
    for j in range(corr.shape[1]):
        value = corr.values[i, j]
        color = custom_colormap(value)
        plt.annotate(f"{value:.2f}", xy=(j, i), ha='center', va='center', color=color)

# Add a colorbar
cbar = plt.colorbar(ticks=[-1, 0, 1])
cbar.ax.set_yticklabels(['-1', '0', '1'])
cbar.set_label("Correlation Coefficient", rotation=270, labelpad=20)

# Set plot title
plt.title("Correlation Heatmap with Custom Colors")

# Set x-axis and y-axis labels
plt.xticks(ticks=np.arange(corr.shape[1]), labels=corr.columns, rotation=45, ha='right')
plt.yticks(ticks=np.arange(corr.shape[0]), labels=corr.index)

# Adjust layout for better label visibility
plt.tight_layout()

# Display the plot
plt.show()


===============================================================================================

from numpy.polynomial.polynomial import Polynomial
from sklearn.metrics import mean_squared_error

degrees = [1, 2, 3, 4]  # Test for various degrees
for degree in degrees:
    poly = Polynomial.fit(X, y, degree)
    y_pred = poly(X)
    mse = mean_squared_error(y, y_pred)
    print(f'Degree {degree}, MSE: {mse}')


import numpy as np
from scipy.optimize import curve_fit

# Define an exponential function
def exponential_func(x, a, b):
    return a * np.exp(b * x)

params, _ = curve_fit(exponential_func, X, y)
y_pred = exponential_func(X, *params)
mse = mean_squared_error(y, y_pred)
print(f'Exponential Model, MSE: {mse}')


from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

degree = 2  # Example for quadratic
model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)
print(f'Cross-validated MSE for degree {degree}: {-scores.mean()}')

============================================================================================

# Example using Pandas DataFrame
df = pd.DataFrame({"Date": date_range, "Value": values})

# Plot directly from DataFrame
df.plot(x="Date", y="Value", figsize=(10, 6))

# Format x-axis to show only the year
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
plt.gca().xaxis.set_major_locator(mdates.YearLocator())

plt.xlabel("Year")
plt.ylabel("Values")
plt.title("Pandas Plot with Year-Only X-Axis Labels")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

__-------------------------------------

import pandas as pd
import numpy as np

# Example training data
train_data = pd.DataFrame({
    'group1': ['A', 'A', 'B', 'B', 'C'],
    'group2': ['X', 'Y', 'X', 'Y', 'X'],
    'feature': [1, 2, np.nan, 4, 5]
})

# Example test data
test_data = pd.DataFrame({
    'group1': ['A', 'B', 'C', 'B', 'C'],
    'group2': ['X', 'Y', 'X', 'X', 'Y'],
    'feature': [np.nan, 3, np.nan, 7, np.nan]
})

# Calculate the mean for each group in training data
group_means = train_data.groupby(['group1', 'group2'])['feature'].mean()

# Define a function to fetch group mean
def impute_with_group_mean(row):
    if pd.isna(row['feature']):
        return group_means.get((row['group1'], row['group2']), np.nan)
    return row['feature']

# Apply the function to the test data
test_data['feature'] = test_data.apply(impute_with_group_mean, axis=1)

print("Train Data:")
print(train_data)
print("\nTest Data After Imputation:")
print(test_data)


_-----------------------------------

import pandas as pd
import numpy as np

# Left DataFrame
left_df = pd.DataFrame({
    'id': [1, 2, 3, 4],
    'value1': [10, np.nan, 30, np.nan],
    'value2': [50, 60, np.nan, np.nan]
})

# Right DataFrame
right_df = pd.DataFrame({
    'id': [2, 3, 4],
    'value1': [20, 35, 40],
    'value2': [55, 65, 70]
})

# Add suffix to left table columns (excluding the join key 'id')
left_df = left_df.rename(columns={col: col + '_left' for col in left_df.columns if col != 'id'})

# Perform the merge
merged_df = pd.merge(left_df, right_df, on='id', how='inner')

# List of columns to impute
columns_to_impute = ['value1', 'value2']

# Impute missing values in left columns with values from the right table
for col in columns_to_impute:
    left_col = col + '_left'
    merged_df[left_col] = merged_df[left_col].fillna(merged_df[col])

# Rename columns back to their original names
merged_df = merged_df.rename(columns={col + '_left': col for col in columns_to_impute})

# Drop the right table columns if not needed
merged_df.drop(columns=columns_to_impute, inplace=True)

print(merged_df)

---------------------------------


import numpy as np
import pandas as pd

class GroupwiseOutlierHandler:
    def __init__(self):
        self.group_bounds = None

    def calculate_bounds(self, group):
        """Calculate IQR-based bounds for a group."""
        Q1 = group['feature'].quantile(0.25)
        Q3 = group['feature'].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        return lower_bound, upper_bound

    def fit(self, train_df, group_col, feature_col):
        """Calculate bounds for outlier detection based on the training set."""
        self.group_col = group_col
        self.feature_col = feature_col

        # Calculate bounds for each group in the training set
        bounds = {}
        for group, group_data in train_df.groupby(group_col):
            lower_bound, upper_bound = self.calculate_bounds(group_data)
            bounds[group] = {'lower_bound': lower_bound, 'upper_bound': upper_bound}

        # Store the bounds
        self.group_bounds = pd.DataFrame(bounds).T
        return self

    def transform(self, df):
        """Apply the calculated bounds to cap outliers in a dataset."""
        if self.group_bounds is None:
            raise ValueError("You must fit the handler before transforming data.")

        def cap_outliers(group):
            group_name = group.name
            lower_bound = self.group_bounds.loc[group_name, 'lower_bound']
            upper_bound = self.group_bounds.loc[group_name, 'upper_bound']
            group[self.feature_col + '_capped'] = np.where(
                group[self.feature_col] < lower_bound, lower_bound,
                np.where(group[self.feature_col] > upper_bound, upper_bound, group[self.feature_col])
            )
            return group

        return df.groupby(self.group_col, group_keys=False).apply(cap_outliers)

    def fit_transform(self, train_df, group_col, feature_col):
        """Fit the bounds on the training set and transform it."""
        self.fit(train_df, group_col, feature_col)
        return self.transform(train_df)

