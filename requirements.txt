TTimport numpy as np
import pandas as pd
from scipy.stats import ttest_ind, mannwhitneyu, ks_2samp, levene, shapiro

# Generate Sample Data
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])

# Function to Perform Hypothesis Testing
def compare_dataframes(df1, df2, alpha=0.05):
    results = []

    for col in df1.columns:
        data1, data2 = df1[col], df2[col]

        # Normality Check (Shapiro-Wilk Test)
        norm1 = shapiro(data1).pvalue > alpha
        norm2 = shapiro(data2).pvalue > alpha

        # T-Test if normal, otherwise Mann-Whitney U Test
        if norm1 and norm2:
            test_stat, p_value_ttest = ttest_ind(data1, data2)
            test_used = "T-Test"
        else:
            test_stat, p_value_ttest = mannwhitneyu(data1, data2)
            test_used = "Mann-Whitney U"

        # Variance Test (Leveneâ€™s Test)
        _, p_value_levene = levene(data1, data2)

        # KS Test for Distribution Similarity
        _, p_value_ks = ks_2samp(data1, data2)

        # Store Results
        results.append({
            "Column": col,
            "Test Used": test_used,
            "T/Mann-Whitney P-Value": p_value_ttest,
            "Levene P-Value (Variance)": p_value_levene,
            "KS P-Value (Distribution)": p_value_ks,
            "Same Mean?": p_value_ttest > alpha,
            "Same Variance?": p_value_levene > alpha,
            "Same Distribution?": p_value_ks > alpha
        })

    return pd.DataFrame(results)

# Run the comparison
results_df = compare_dataframes(df1, df2)
print(results_df)



import numpy as np
import pandas as pd

def permutation_test(df1, df2, num_permutations=10000, alpha=0.05):
    results = []
    
    for col in df1.columns:
        data1, data2 = df1[col].values, df2[col].values
        observed_diff = np.mean(data1) - np.mean(data2)  # Step 1: Observed difference

        # Step 2: Compute permuted mean differences
        combined = np.concatenate([data1, data2])
        perm_diffs = []
        for _ in range(num_permutations):
            np.random.shuffle(combined)  # Shuffle combined data
            perm_diffs.append(np.mean(combined[:len(data1)]) - np.mean(combined[len(data1):]))

        # Step 3: Compute empirical p-value
        perm_diffs = np.array(perm_diffs)
        p_value = np.mean(np.abs(perm_diffs) >= np.abs(observed_diff))

        # Store results
        results.append({
            "Column": col,
            "Observed Difference": observed_diff,
            "P-Value": p_value,
            "Significant?": p_value < alpha  # Reject null if p < alpha
        })

    return pd.DataFrame(results)

# Example Usage
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(51, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])  # Slightly different mean

# Run the permutation test
perm_results = permutation_test(df1, df2)
print(perm_results)


import numpy as np
import pandas as pd
from scipy.stats import f_oneway

def anova_test(df1, df2, alpha=0.05):
    results = []
    
    for col in df1.columns:
        data1, data2 = df1[col], df2[col]
        
        # Perform One-Way ANOVA
        f_stat, p_value = f_oneway(data1, data2)

        # Store results
        results.append({
            "Column": col,
            "F-Statistic": f_stat,
            "P-Value": p_value,
            "Significant?": p_value < alpha  # Reject null if p < alpha
        })
    
    return pd.DataFrame(results)

# Example Usage
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(51, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])  # Slightly different mean

anova_results = anova_test(df1, df2)
print(anova_results)


import numpy as np
import pandas as pd
from scipy.stats import pearsonr, spearmanr

# Generate synthetic data
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(51, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])

def correlation_tests(df1, df2):
    results = []
    for col in df1.columns:
        pearson_corr, _ = pearsonr(df1[col], df2[col])
        spearman_corr, _ = spearmanr(df1[col], df2[col])
        results.append({"Column": col, "Pearson Correlation": pearson_corr, "Spearman Correlation": spearman_corr})
    
    return pd.DataFrame(results)

# Run tests
corr_results = correlation_tests(df1, df2)
print(corr_results)
from scipy.stats import entropy

def kl_divergence(df1, df2, bins=20):
    results = []
    for col in df1.columns:
        hist1, _ = np.histogram(df1[col], bins=bins, density=True)
        hist2, _ = np.histogram(df2[col], bins=bins, density=True)

        # Normalize histograms to form probability distributions
        hist1 = hist1 / np.sum(hist1)
        hist2 = hist2 / np.sum(hist2)

        kl_div = entropy(hist1, hist2)  # KL divergence
        results.append({"Column": col, "KL Divergence": kl_div})
    
    return pd.DataFrame(results)

# Run KL test
kl_results = kl_divergence(df1, df2)
print(kl_results)



{
  "editor.formatOnSave": true,
  "editor.suggestSelection": "first",
  "files.autoSave": "afterDelay",
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/*.pyc": {
      "when": "$(basename).py"
    },
    "**/_pycache_": true,
    ".pytest_cache": true
  },
  "files.trimTrailingWhitespace": true,
  "workbench.startupEditor": "newUntitledFile",
  "win-ca.inject": "append",
  "workbench.colorTheme": "Visual Studio Light",
  "editor.fontSize": 17,
  "git.autofetch": true,
  "snowflake.connections ConfigFile": "C:\\Users\\t057831\\.snowflake\\connections.toml",
  "workbench.preferredHighContrastColorTheme": "Default Dark Modern",
  "editor.rename.enablePreview": false,
  "editor.semanticTokenColorCustomizations": {}
}


Custom Tooltip =
VAR ActualValue = SELECTEDVALUE(YourTable[Actual])
VAR UpperValue = SELECTEDVALUE(YourTable[Upper])
VAR LowerValue = SELECTEDVALUE(YourTable[Lower])
VAR PredictionValue = SELECTEDVALUE(YourTable[Prediction])

VAR DisplayUpper = IF(ActualValue = UpperValue, BLANK(), UpperValue)
VAR DisplayLower = IF(ActualValue = LowerValue, BLANK(), LowerValue)

RETURN 
"Actual: " & ActualValue & UNICHAR(10) & 
IF(NOT(ISBLANK(DisplayUpper)), "Upper: " & DisplayUpper & UNICHAR(10), "") & 
"Prediction: " & PredictionValue & UNICHAR(10) & 
IF(NOT(ISBLANK(DisplayLower)), "Lower: " & DisplayLower, "")



Investment Gain and Investment Income are related but distinct financial concepts:

1. Investment Gain refers to the increase in the value of an investment over time. It includes:

Capital Gains: The profit earned from selling an asset (e.g., stocks, real estate) for more than its purchase price.

Unrealized Gains: The increase in value of an asset that has not yet been sold.



2. Investment Income refers to the regular earnings generated by an investment. It includes:

Dividends: Payments made by companies to shareholders.

Interest: Earnings from fixed-income investments like bonds or savings accounts.

Rental Income: Earnings from real estate properties.




from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# Load model and tokenizer
model_id = "bigcode/starcoder2-3b"

print("Loading tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(model_id)

print("Loading model...")
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float32,  # You have enough RAM, use float32 for max compatibility
    device_map="auto"           # Will use CPU across all cores
)

# Prompt to generate Python code
prompt = """# Write a Python script to fetch data from an API and save it to a CSV file
"""

print("Tokenizing...")
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

print("Generating...")
outputs = model.generate(
    **inputs,
    max_new_tokens=150,           # You can increase this for longer code
    do_sample=True,               # Enable sampling for creativity
    top_p=0.95,
    temperature=0.7,
    pad_token_id=tokenizer.eos_token_id
)

generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)
print("\n=== Generated Python Code ===\n")
print(generated_code)


import os
import psutil

def get_readable_size(bytes_val):
    return f"{bytes_val / (1024 ** 3):.2f} GB"

def get_dir_size(path):
    total = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            total += os.path.getsize(fp)
    return total

# 1. RAM Info
mem = psutil.virtual_memory()
print(f"=== RAM Info ===")
print(f"Total RAM: {get_readable_size(mem.total)}")
print(f"Available RAM: {get_readable_size(mem.available)}\n")

# 2. Disk Info
disk = psutil.disk_usage('/')
print(f"=== Disk Info ===")
print(f"Total Disk: {get_readable_size(disk.total)}")
print(f"Free Disk: {get_readable_size(disk.free)}\n")

# 3. Hugging Face Cache Info
cache_path = os.path.expanduser("~/.cache/huggingface")
if os.path.exists(cache_path):
    cache_size = get_dir_size(cache_path)
    print(f"=== Hugging Face Cache ===")
    print(f"Cache Directory: {cache_path}")
    print(f"Cache Size: {get_readable_size(cache_size)}")
else:
    print("Hugging Face cache directory not found.")

import shutil
import os

cache_path = os.path.expanduser("~/.cache/huggingface")
if os.path.exists(cache_path):
    shutil.rmtree(cache_path)
    print("Hugging Face cache (models, tokenizers, etc.) deleted.")
else:
    print("No Hugging Face cache found.")



import ast
import astor

class CodeInjector(ast.NodeTransformer):
    def __init__(self, method_name, code_to_insert):
        self.method_name = method_name
        self.code_to_insert = code_to_insert

    def visit_FunctionDef(self, node):
        if node.name == self.method_name:
            new_nodes = ast.parse(self.code_to_insert).body
            node.body = new_nodes + node.body  # Insert at start; use node.body + new_nodes to insert at end
        return node

# Sample usage
with open("your_file.py", "r") as f:
    source = f.read()

tree = ast.parse(source)
injector = CodeInjector(method_name="target_method", code_to_insert="print('Injected code')")
modified_tree = injector.visit(tree)

with open("your_file_modified.py", "w") as f:
    f.write(astor.to_source(modified_tree))



import ast
import astor

class SmartCodeInjector(ast.NodeTransformer):
    def __init__(self, method_name, after_string=None, before_return_code=None):
        self.method_name = method_name
        self.after_string = after_string
        self.before_return_code = before_return_code

    def visit_FunctionDef(self, node):
        if node.name != self.method_name:
            return node

        new_body = []
        for stmt in node.body:
            # If it's a print("some string") and matches the given one
            if (
                isinstance(stmt, ast.Expr)
                and isinstance(stmt.value, ast.Call)
                and isinstance(stmt.value.func, ast.Name)
                and stmt.value.func.id == "print"
                and len(stmt.value.args) > 0
                and isinstance(stmt.value.args[0], ast.Constant)
                and stmt.value.args[0].value == self.after_string
            ):
                new_body.append(stmt)
                # Insert after the matched print
                new_body += ast.parse("print('injected after string')").body
            elif isinstance(stmt, ast.Return):
                # Insert before return
                new_body += ast.parse(self.before_return_code).body
                new_body.append(stmt)
            else:
                new_body.append(stmt)

        node.body = new_body
        return node