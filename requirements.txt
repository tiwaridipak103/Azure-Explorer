TTimport numpy as np
import pandas as pd
from scipy.stats import ttest_ind, mannwhitneyu, ks_2samp, levene, shapiro

# Generate Sample Data
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])

# Function to Perform Hypothesis Testing
def compare_dataframes(df1, df2, alpha=0.05):
    results = []

    for col in df1.columns:
        data1, data2 = df1[col], df2[col]

        # Normality Check (Shapiro-Wilk Test)
        norm1 = shapiro(data1).pvalue > alpha
        norm2 = shapiro(data2).pvalue > alpha

        # T-Test if normal, otherwise Mann-Whitney U Test
        if norm1 and norm2:
            test_stat, p_value_ttest = ttest_ind(data1, data2)
            test_used = "T-Test"
        else:
            test_stat, p_value_ttest = mannwhitneyu(data1, data2)
            test_used = "Mann-Whitney U"

        # Variance Test (Levene’s Test)
        _, p_value_levene = levene(data1, data2)

        # KS Test for Distribution Similarity
        _, p_value_ks = ks_2samp(data1, data2)

        # Store Results
        results.append({
            "Column": col,
            "Test Used": test_used,
            "T/Mann-Whitney P-Value": p_value_ttest,
            "Levene P-Value (Variance)": p_value_levene,
            "KS P-Value (Distribution)": p_value_ks,
            "Same Mean?": p_value_ttest > alpha,
            "Same Variance?": p_value_levene > alpha,
            "Same Distribution?": p_value_ks > alpha
        })

    return pd.DataFrame(results)

# Run the comparison
results_df = compare_dataframes(df1, df2)
print(results_df)



import numpy as np
import pandas as pd

def permutation_test(df1, df2, num_permutations=10000, alpha=0.05):
    results = []
    
    for col in df1.columns:
        data1, data2 = df1[col].values, df2[col].values
        observed_diff = np.mean(data1) - np.mean(data2)  # Step 1: Observed difference

        # Step 2: Compute permuted mean differences
        combined = np.concatenate([data1, data2])
        perm_diffs = []
        for _ in range(num_permutations):
            np.random.shuffle(combined)  # Shuffle combined data
            perm_diffs.append(np.mean(combined[:len(data1)]) - np.mean(combined[len(data1):]))

        # Step 3: Compute empirical p-value
        perm_diffs = np.array(perm_diffs)
        p_value = np.mean(np.abs(perm_diffs) >= np.abs(observed_diff))

        # Store results
        results.append({
            "Column": col,
            "Observed Difference": observed_diff,
            "P-Value": p_value,
            "Significant?": p_value < alpha  # Reject null if p < alpha
        })

    return pd.DataFrame(results)

# Example Usage
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(51, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])  # Slightly different mean

# Run the permutation test
perm_results = permutation_test(df1, df2)
print(perm_results)


import numpy as np
import pandas as pd
from scipy.stats import f_oneway

def anova_test(df1, df2, alpha=0.05):
    results = []
    
    for col in df1.columns:
        data1, data2 = df1[col], df2[col]
        
        # Perform One-Way ANOVA
        f_stat, p_value = f_oneway(data1, data2)

        # Store results
        results.append({
            "Column": col,
            "F-Statistic": f_stat,
            "P-Value": p_value,
            "Significant?": p_value < alpha  # Reject null if p < alpha
        })
    
    return pd.DataFrame(results)

# Example Usage
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(51, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])  # Slightly different mean

anova_results = anova_test(df1, df2)
print(anova_results)


import numpy as np
import pandas as pd
from scipy.stats import pearsonr, spearmanr

# Generate synthetic data
np.random.seed(42)
df1 = pd.DataFrame(np.random.normal(50, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])
df2 = pd.DataFrame(np.random.normal(51, 10, (100, 20)), columns=[f"col_{i}" for i in range(20)])

def correlation_tests(df1, df2):
    results = []
    for col in df1.columns:
        pearson_corr, _ = pearsonr(df1[col], df2[col])
        spearman_corr, _ = spearmanr(df1[col], df2[col])
        results.append({"Column": col, "Pearson Correlation": pearson_corr, "Spearman Correlation": spearman_corr})
    
    return pd.DataFrame(results)

# Run tests
corr_results = correlation_tests(df1, df2)
print(corr_results)
from scipy.stats import entropy

def kl_divergence(df1, df2, bins=20):
    results = []
    for col in df1.columns:
        hist1, _ = np.histogram(df1[col], bins=bins, density=True)
        hist2, _ = np.histogram(df2[col], bins=bins, density=True)

        # Normalize histograms to form probability distributions
        hist1 = hist1 / np.sum(hist1)
        hist2 = hist2 / np.sum(hist2)

        kl_div = entropy(hist1, hist2)  # KL divergence
        results.append({"Column": col, "KL Divergence": kl_div})
    
    return pd.DataFrame(results)

# Run KL test
kl_results = kl_divergence(df1, df2)
print(kl_results)



{
  "editor.formatOnSave": true,
  "editor.suggestSelection": "first",
  "files.autoSave": "afterDelay",
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/*.pyc": {
      "when": "$(basename).py"
    },
    "**/_pycache_": true,
    ".pytest_cache": true
  },
  "files.trimTrailingWhitespace": true,
  "workbench.startupEditor": "newUntitledFile",
  "win-ca.inject": "append",
  "workbench.colorTheme": "Visual Studio Light",
  "editor.fontSize": 17,
  "git.autofetch": true,
  "snowflake.connections ConfigFile": "C:\\Users\\t057831\\.snowflake\\connections.toml",
  "workbench.preferredHighContrastColorTheme": "Default Dark Modern",
  "editor.rename.enablePreview": false,
  "editor.semanticTokenColorCustomizations": {}
}


Custom Tooltip =
VAR ActualValue = SELECTEDVALUE(YourTable[Actual])
VAR UpperValue = SELECTEDVALUE(YourTable[Upper])
VAR LowerValue = SELECTEDVALUE(YourTable[Lower])
VAR PredictionValue = SELECTEDVALUE(YourTable[Prediction])

VAR DisplayUpper = IF(ActualValue = UpperValue, BLANK(), UpperValue)
VAR DisplayLower = IF(ActualValue = LowerValue, BLANK(), LowerValue)

RETURN 
"Actual: " & ActualValue & UNICHAR(10) & 
IF(NOT(ISBLANK(DisplayUpper)), "Upper: " & DisplayUpper & UNICHAR(10), "") & 
"Prediction: " & PredictionValue & UNICHAR(10) & 
IF(NOT(ISBLANK(DisplayLower)), "Lower: " & DisplayLower, "")



Investment Gain and Investment Income are related but distinct financial concepts:

1. Investment Gain refers to the increase in the value of an investment over time. It includes:

Capital Gains: The profit earned from selling an asset (e.g., stocks, real estate) for more than its purchase price.

Unrealized Gains: The increase in value of an asset that has not yet been sold.



2. Investment Income refers to the regular earnings generated by an investment. It includes:

Dividends: Payments made by companies to shareholders.

Interest: Earnings from fixed-income investments like bonds or savings accounts.

Rental Income: Earnings from real estate properties.




In summary, investment gain is typically associated with asset appreciation, while investment income comes from ongoing earnings like dividends and interest.


[Your Name]
[Your Address]
[Your Email]
[Your Phone Number]
[Date]

Admissions Committee
Worcester Polytechnic Institute
[Address of the University]

Subject: Recommendation for [Colleague's Name] – MS in Business Analytics Application

Dear Admissions Committee,

I am honored to write this letter of recommendation for [Colleague’s Name] in support of her application for the Master of Science in Business Analytics at Worcester Polytechnic Institute. Having worked alongside her for nearly three years in the Data Science and Analytics team at Morgan Stanley, I have had the privilege of witnessing her exceptional analytical skills, problem-solving acumen, and unwavering dedication to excellence.

During our tenure together, [Colleague’s Name] consistently demonstrated a deep understanding of data analytics, statistical modeling, and business intelligence. She played an instrumental role in deriving actionable insights from complex datasets, enabling key stakeholders to make informed decisions. Her ability to blend technical expertise with strategic thinking made her an invaluable asset to our team.

One of the standout qualities of [Colleague’s Name] is her keen attention to detail and her ability to transform raw data into meaningful narratives. She exhibited exceptional proficiency in tools such as Python, SQL, Tableau, and Power BI, allowing her to craft insightful reports and dashboards that streamlined decision-making processes. Furthermore, her strong grasp of machine learning and predictive analytics contributed significantly to optimizing financial models and risk assessment strategies.

Beyond her technical prowess, [Colleague’s Name] is an excellent team player who thrives in collaborative environments. She has a remarkable ability to communicate complex data-driven insights in a clear and concise manner, making her an effective liaison between technical teams and business stakeholders. Her leadership, adaptability, and eagerness to continuously learn set her apart as a professional committed to personal and professional growth.

I have no doubt that [Colleague’s Name] will excel in WPI’s MS in Business Analytics program. Her analytical mindset, combined with her passion for leveraging data to drive impactful business decisions, makes her an ideal candidate for this prestigious program. I wholeheartedly endorse her application and strongly believe that she will contribute significantly to your academic community.

Please feel free to contact me at [Your Email] or [Your Phone Number] if you require any additional information.

Sincerely,
[Your Name]
[Your Position]
Morgan Stanley (Formerly)
[Your Contact Information]


from scipy.stats import anderson_ksamp

result = anderson_ksamp([df1['values'], df2['values']])
print(f"Anderson-Darling Test Statistic: {result.statistic}, P-value: {result.significance_level}")

from scipy.stats import chisquare

df1_counts, _ = np.histogram(df1['values'], bins=10)
df2_counts, _ = np.histogram(df2['values'], bins=10)

chi_stat, chi_p_value = chisquare(df1_counts, df2_counts)
print(f"Chi-Square Statistic: {chi_stat}, P-value: {chi_p_value}")


import numpy as np
import pandas as pd

def calculate_psi(expected, actual, bins=10):
    """Calculate PSI between two distributions."""
    
    # Define bin edges based on the expected data
    bin_edges = np.linspace(expected.min(), expected.max(), bins + 1)
    
    # Assign data to bins
    expected_bins = np.histogram(expected, bins=bin_edges)[0] / len(expected)
    actual_bins = np.histogram(actual, bins=bin_edges)[0] / len(actual)

    # Replace zeroes to avoid log(0)
    expected_bins = np.where(expected_bins == 0, 0.0001, expected_bins)
    actual_bins = np.where(actual_bins == 0, 0.0001, actual_bins)

    # Compute PSI
    psi_values = (expected_bins - actual_bins) * np.log(expected_bins / actual_bins)
    psi = np.sum(psi_values)

    return psi

# Example Data
df1 = pd.DataFrame({'values': np.random.normal(0, 1, 1000)})  # Baseline distribution
df2 = pd.DataFrame({'values': np.random.normal(0.2, 1.2, 1000)})  # New distribution

psi_value = calculate_psi(df1['values'], df2['values'])
print(f"PSI Score: {psi_value}")

# Interpretation
if psi_value < 0.1:
    print("No significant shift in distribution (Stable).")
elif psi_value < 0.25:
    print("Moderate shift in distribution (Needs monitoring).")
else:
    print("Significant shift in distribution (Action required).")


import pandas as pd
import numpy as np

def calculate_psi(expected, actual, bins=10):
    """Calculate PSI between two distributions."""
    bin_edges = np.linspace(expected.min(), expected.max(), bins + 1)
    
    expected_bins = np.histogram(expected, bins=bin_edges)[0] / len(expected)
    actual_bins = np.histogram(actual, bins=bin_edges)[0] / len(actual)

    expected_bins = np.where(expected_bins == 0, 0.0001, expected_bins)
    actual_bins = np.where(actual_bins == 0, 0.0001, actual_bins)

    psi_values = (expected_bins - actual_bins) * np.log(expected_bins / actual_bins)
    psi = np.sum(psi_values)

    return psi

# Example Usage:
for col in df.columns:
    psi_value = calculate_psi(df.loc[df['year'] <= 2025, col], df.loc[df['year'] > 2025, col])
    print(f"PSI for {col}: {psi_value}")


from scipy.stats import ks_2samp

for col in df.columns:
    ks_stat, p_value = ks_2samp(df.loc[df['year'] <= 2025, col], df.loc[df['year'] > 2025, col])
    print(f"KS Test for {col}: p-value={p_value}")

    if p_value < 0.05:
        print(f"Significant drift detected in {col}")

df['residuals'] = df['actual_values'] - df['predicted_values']
plt.plot(df['year'], df['residuals'])
plt.axhline(0, color='red', linestyle='--')
plt.show()

import pandas as pd
import numpy as np
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, TargetDriftPreset
from evidently.dashboard import Dashboard

# Load dataset
df = pd.read_csv("your_timeseries_data.csv")  # Replace with actual dataset path

# Splitting into reference (historical) and current (future)
reference_data = df[df["year"] <= 2025].drop(columns=["year"])  # Training period
current_data = df[df["year"] > 2025].drop(columns=["year"])  # Future period

# Ensure both datasets have the same columns
assert reference_data.columns.equals(current_data.columns), "Column mismatch between reference and current data"

# Generate Data Drift Report
data_drift_report = Report(metrics=[DataDriftPreset()])
data_drift_report.run(reference_data=reference_data, current_data=current_data)
data_drift_report.show()

# Generate Target Drift Report (If you have a target variable)
target_column = "your_target_column"  # Replace with the actual target column name
target_drift_report = Report(metrics=[TargetDriftPreset()])
target_drift_report.run(reference_data=reference_data, current_data=current_data, column_mapping={"target": target_column})
target_drift_report.show()

# Interactive Dashboard for Continuous Monitoring
dashboard = Dashboard(metrics=[DataDriftPreset()])
dashboard.run(reference_data=reference_data, current_data=current_data)
dashboard.show()


from evidently import ColumnType
from evidently.report import Report
from evidently.metrics import DataDriftPreset

# List of all drift detection methods for numeric data
numeric_methods = [
    "ks", "wasserstein", "kl_div", "psi", "anderson",
    "cramer_von_mises", "hellinger", "mannw", "ed", 
    "es", "t_test", "empirical_mmd"
]

# Apply all numeric drift methods while keeping the default threshold
report = Report([
    DataDriftPreset(
        per_column_method={col: numeric_methods for col in numeric_columns}
    )
])

# Run the report on the datasets
snapshot = report.run(reference_data, current_data)

# Display the report
snapshot